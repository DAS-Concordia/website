---
title: AI and TODO Comments A New Way to Think About Code Generation 

authors:
  name: David OBrien 
  title: Ph.D Student  
  url: https://davidmobrien.github.io/
---

<h2>AI and TODO Comments: A New Way to Think About Code Generation </h2> 

Every developer has written a TODO comment at some point in their code. Whether it's a simple reminder to fix a bug, mark unfinished work, or indicate a piece of technical debt, these short notes have been a go-to method for flagging issues for later. But with the rise of AI-powered tools like GitHub Copilot, these TODOs may be taking on a whole new purpose. So, what happens when AI tools, like Copilot, come across these comments? Do they help, ignore, or maybe even make things worse? 

In recent studies, developers have been diving into how AI handles TODO comments, seeing if these familiar notes can help streamline coding or if they lead to new challenges. 

**How AI Handles TODO : A Ne0w Way to Think About Code Generation** 

AI tools like GitHub Copilot use machine learning to understand patterns in code. They’re trained on vast amounts of open-source code, learning from it to predict and generate code based on prompts. So, when a TODO comment is placed in the code, the AI analyzes it to generate relevant code that could potentially solve the issue described. But how well does it work? 

Based on research, it turns out that when TODO comments are clear and specific, AI tools like Copilot do a solid job of generating useful code. For example, if a TODO comment says, “Add user authentication logic,” Copilot knows exactly what kind of code to generate. But when the comment is vague, like “Fix this later,” the AI might not know what to do with it and will often end up suggesting redundant or unhelpful code. 

**AI's Struggles and Surprises: When Things Go Right and Wrong** 

While Copilot can be impressive, it’s not perfect. Sometimes, instead of fixing issues, the AI ends up reproducing technical debt, copying over the same problems that were originally flagged in the TODO. This is a common pitfall of relying too heavily on AI without providing enough context or clear direction. 

On the other hand, there are times when Copilot does more than just fix what's broken it improves the code in ways developers didn’t even ask for. For example, in one case, a vague TODO about performance was turned into optimized code that was much better than expected. While this may not happen every time, it shows the potential of AI to go beyond simple code generation. 

**Making AI More Useful: How Developers Can Help** 

The takeaway here is simple: AI tools are only as effective as the input they’re given. If developers want to get the most out of these tools, they need to write clear, specific TODO comments. Instead of saying something vague like “Fix this,” they should offer actionable instructions. For instance, “Refactor this loop to improve performance” gives Copilot a much clearer direction, making it easier for the AI to generate useful code. 

But AI is not a replacement for human judgment. Even with a great TODO comment, developers still need to review and refine the code that AI generates, ensuring that it meets the project's standards and quality. 
